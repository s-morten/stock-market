{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2b2b2f",
   "metadata": {},
   "source": [
    "search for 5+% losses. analyse the behavior prior and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a51c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dax = [\"ADS.DE\", \"AIR.PA\", \"ALV.DE\", \"BAS.DE\", \"BAYN.DE\", \"BEI.DE\", \"BMW.DE\", \"BNR.DE\", \"CBK.DE\", \"CON.DE\", \"1COV.DE\", \"DTG.DE\", \"DBK.DE\", \"DB1.DE\", \"DHL.DE\", \"DTE.DE\", \"EOAN.DE\", \"FRE.DE\", \"FME.DE\", \"HNR1.DE\", \"HEI.DE\", \"HEN3.DE\", \"IFX.DE\", \"MBG.DE\", \"MRK.DE\", \"MTX.DE\", \"MUV2.DE\", \"PAH3.DE\", \"P911.DE\", \"QIA.DE\", \"RHM.DE\", \"RWE.DE\", \"SAP.DE\", \"SRT3.DE\", \"SIE.DE\", \"ENR.DE\", \"SHL.DE\", \"SY1.DE\", \"VOW3.DE\", \"VNA.DE\", \"ZAL.DE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbcdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full implementation method (recommended):\n",
    "import pandas as pd\n",
    "def get_sp500_tickers():\n",
    "    table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    df = table[0]\n",
    "    return df['Symbol'].tolist()\n",
    "\n",
    "# Usage:\n",
    "sp500_tickers = get_sp500_tickers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292cca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = yf.download(sp500_tickers, start=\"2015-01-01\", end=\"2025-05-01\", interval=\"1d\")\n",
    "data = yf.download(dax, start=\"2015-01-01\", end=\"2025-05-01\", interval=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d07c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SPY = yf.download(\"SPY\", start=\"2015-01-01\", end=\"2025-05-01\", interval=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41689eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SPY = df_SPY.stack(level=1).rename_axis(['Date', 'Ticker']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.stack(level=1).rename_axis(['Date', 'Ticker']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to ensure chronological order\n",
    "df = df.sort_values(by=['Ticker', 'Date'])\n",
    "\n",
    "# Group by ticker and calculate % changes\n",
    "df['Prev_Close'] = df.groupby('Ticker')['Close'].shift(1)\n",
    "\n",
    "df['Day_Pct'] = df['Close'] / df['Open'] - 1\n",
    "df['Night_Pct'] = df['Open'] / df['Prev_Close'] - 1\n",
    "\n",
    "# Identify where either drop exceeds -5%\n",
    "drop_mask = (df['Day_Pct'] <= -0.1) | (df['Night_Pct'] <= -0.1)\n",
    "drop_points = df[drop_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to ensure chronological order\n",
    "df_SPY = df_SPY.sort_values(by=['Ticker', 'Date'])\n",
    "\n",
    "# Group by ticker and calculate % changes\n",
    "df_SPY['Prev_Close'] = df_SPY.groupby('Ticker')['Close'].shift(1)\n",
    "\n",
    "df_SPY['Day_Pct'] = df_SPY['Close'] / df_SPY['Open'] - 1\n",
    "df_SPY['Night_Pct'] = df_SPY['Open'] / df_SPY['Prev_Close'] - 1\n",
    "\n",
    "# Identify where either drop exceeds -5%\n",
    "drop_mask_SPY = (df_SPY['Day_Pct'] <= -0.05) | (df_SPY['Night_Pct'] <= -0.05)\n",
    "drop_points_SPY = df_SPY[drop_mask_SPY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_points_filter = drop_points[~drop_points[\"Date\"].isin(drop_points_SPY[\"Date\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44057ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate time difference between current and previous row within same ID\n",
    "# drop_points_filter['Date_Diff'] = drop_points_filter.groupby('Ticker')['Date'].diff()\n",
    "\n",
    "# # Mark entries where the date difference is less than 30 days\n",
    "# drop_points_filter['Remove'] = drop_points_filter['Date_Diff'].dt.days < 30\n",
    "\n",
    "# # Fill NA (first entry per group) with False\n",
    "# drop_points_filter['Remove'] = drop_points_filter['Remove'].fillna(False)\n",
    "\n",
    "# # Keep only rows not marked for removal\n",
    "# drop_points_filter = drop_points_filter[~drop_points_filter['Remove']].drop(columns=['Date_Diff', 'Remove'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final results container\n",
    "results = []\n",
    "\n",
    "# Loop over each drop\n",
    "for _, row in drop_points_filter.iterrows():\n",
    "    ticker = row['Ticker']\n",
    "    drop_date = row['Date']\n",
    "    drop_pct = min(row['Day_Pct'], row['Night_Pct'])\n",
    "\n",
    "    # Define windows\n",
    "    start_date_before3 = drop_date - pd.DateOffset(months=3)\n",
    "    start_date_after3 = drop_date + pd.DateOffset(months=3)\n",
    "    \n",
    "    start_date_before2 = drop_date - pd.DateOffset(months=2)\n",
    "    start_date_after2 = drop_date + pd.DateOffset(months=2)\n",
    "    \n",
    "    start_date_before1 = drop_date - pd.DateOffset(months=1)\n",
    "    start_date_after1 = drop_date + pd.DateOffset(months=1)\n",
    "\n",
    "    day_before_drop = drop_date - pd.DateOffset(days=1)\n",
    "    day_after_drop = drop_date + pd.DateOffset(days=1)\n",
    "    \n",
    "    # Extract price 3 months before and after\n",
    "    ticker_df = df[df['Ticker'] == ticker].set_index('Date')\n",
    "\n",
    "    try:\n",
    "        three_months = {}\n",
    "        for start_date_before, start_date_after, months in [(start_date_before3, start_date_after3, 3), (start_date_before2, start_date_after2, 2), (start_date_before1, start_date_after1, 1)]:\n",
    "            price_before = ticker_df.loc[start_date_before:, 'Close'].iloc[0]\n",
    "            price_before_drop_day = (ticker_df.loc[day_before_drop:, 'Close'].iloc[0] + ticker_df.loc[day_before_drop:, 'Open'].iloc[0]) / 2\n",
    "            price_after_drop_day = (ticker_df.loc[day_after_drop:, 'Close'].iloc[0] + ticker_df.loc[day_after_drop:, 'Open'].iloc[0]) / 2\n",
    "            price_after = ticker_df.loc[start_date_after:, 'Close'].iloc[0]\n",
    "\n",
    "            pct_change_before = (price_before_drop_day / price_before) - 1\n",
    "            pct_change_after = (price_after / price_after_drop_day) - 1\n",
    "            three_months[f\"Pct_Change_Before_{months}M\"] = pct_change_before\n",
    "            three_months[f\"Pct_Change_After_{months}M\"] = pct_change_after\n",
    "\n",
    "        results.append({\n",
    "            'Ticker': ticker,\n",
    "            'Drop_Date': drop_date,\n",
    "            'Drop_Percentage': drop_pct,\n",
    "            **three_months\n",
    "        })\n",
    "    except IndexError:\n",
    "        # If before/after data is missing (e.g., start/end of dataset)\n",
    "        continue\n",
    "\n",
    "# Create final DataFrame\n",
    "final_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74137ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sell point detection: \n",
    "#   A: drop of 10%\n",
    "#   B: momentum shifts\n",
    "lookback_period_long = 90\n",
    "lookback_period_short = 30\n",
    "\n",
    "# get start date\n",
    "def invest_journey(row):\n",
    "    df_ticker = df[(df[\"Ticker\"] == row[\"Ticker\"]) & (df[\"Date\"] > row[\"Drop_Date\"])].copy()\n",
    "    df_ticker.reset_index(drop=True, inplace=True)\n",
    "    buy_price = df_ticker.head(1).High.iloc[0]\n",
    "    buy_date = df_ticker.head(1).Date.iloc[0]\n",
    "    df_ticker[\"momentum_long\"] = df_ticker['Close'].rolling(window=lookback_period_long).mean()\n",
    "    df_ticker[\"momentum_short\"] = df_ticker['Close'].rolling(window=lookback_period_short).mean()\n",
    "    df_ticker[\"gain\"] = df_ticker[\"Close\"].pct_change(periods=1).cumsum()\n",
    "    df_ticker[\"sell\"] = np.where((df_ticker[\"momentum_long\"] > df_ticker[\"momentum_short\"]), 1, 0) #(df_ticker[\"gain\"] < -0.15) |  | (df_ticker[\"Day_Pct\"] < -0.1) | (df_ticker[\"Night_Pct\"] < -0.1) \n",
    "    if df_ticker[df_ticker[\"sell\"] == 1].shape[0] == 0:\n",
    "        sell_price = df_ticker.iloc[[-1]].Low.iloc[0]\n",
    "        sell_date = df_ticker.iloc[[-1]].Date.iloc[0]      \n",
    "        # manipulate for percentages\n",
    "        df_ticker.iloc[[-1]][\"Close\"] = sell_price\n",
    "        df_ticker.loc[0, 'Close'] = buy_price\n",
    "        df_ticker['Pct_Change'] = df_ticker['Close'].pct_change(periods=1)\n",
    "    else:    \n",
    "        sell_price = df_ticker.iloc[df_ticker[df_ticker[\"Date\"] == (df_ticker.loc[df_ticker[\"sell\"] == 1, \"Date\"].min())].index + 1].Low.iloc[0]\n",
    "        sell_date = df_ticker.iloc[df_ticker[df_ticker[\"Date\"] == (df_ticker.loc[df_ticker[\"sell\"] == 1, \"Date\"].min())].index + 1].Date.iloc[0]\n",
    "        # manipulate for percentages\n",
    "        df_ticker.loc[df_ticker[df_ticker[\"Date\"] == (df_ticker.loc[df_ticker[\"sell\"] == 1, \"Date\"].min())].index + 1, \"Close\"] = sell_price\n",
    "        df_ticker.loc[0, 'Close'] = buy_price\n",
    "        df_ticker['Pct_Change'] = df_ticker['Close'].pct_change(periods=1)\n",
    "    return [row[\"Ticker\"], row[\"Drop_Date\"], buy_price, sell_price, sell_price / buy_price - 1, buy_date, sell_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for _, row in final_df.iterrows():\n",
    "    results.append(invest_journey(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c979c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"Ticker\", \"Drop_Date\", \"Buy_Price\", \"Sell_Price\", \"Pct_Change\", \"Buy Date\", \"Sell Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c94557",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"Pct_Change\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282dfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.DataFrame({\n",
    "    'id': pd.concat([results_df['Ticker'], results_df['Ticker']]).values,\n",
    "    'date': pd.concat([results_df['Buy Date'], results_df['Sell Date']]).values,\n",
    "    'value': pd.concat([pd.Series([pd.NA] * len(results_df)), results_df['Pct_Change']]).values, \n",
    "    'category': ['Buy'] * len(results_df) + ['Sell'] * len(results_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = 200\n",
    "\n",
    "for row in df_long.iterrows():\n",
    "    if row[1][\"category\"] == \"Buy\":\n",
    "        portfolio += row[1][\"value\"] * portfolio\n",
    "    else:\n",
    "        portfolio += row[1][\"value\"] * portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513717a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define bins from -1.0 to 1.0 in steps of 0.1\n",
    "bins = np.arange(-1.0, 1.1, 0.1)\n",
    "\n",
    "# Create labels for each bin\n",
    "labels = [f\"{round(bins[i],1)} to {round(bins[i+1],1)}\" for i in range(len(bins)-1)]\n",
    "\n",
    "# Bin the data\n",
    "for m in [\"3M\", \"2M\", \"1M\"]:\n",
    "    final_df[f'Pct_After_Bin_{m}'] = pd.cut(final_df[f'Pct_Change_After_{m}'], bins=bins, labels=labels, include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences in each bin\n",
    "histogram = final_df['Pct_After_Bin_1M'].value_counts().sort_index().reset_index()\n",
    "histogram.columns = ['Pct_Change_Range', 'Count_1M']\n",
    "\n",
    "h2M = final_df['Pct_After_Bin_2M'].value_counts().sort_index().reset_index()\n",
    "h2M.columns = ['Pct_Change_Range', 'Count_2M']\n",
    "\n",
    "h3M = final_df['Pct_After_Bin_3M'].value_counts().sort_index().reset_index()\n",
    "h3M.columns = ['Pct_Change_Range', 'Count_3M']\n",
    "\n",
    "histogram = pd.merge(histogram, h2M, on='Pct_Change_Range')\n",
    "histogram = pd.merge(histogram, h3M, on='Pct_Change_Range')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram[\"Count_1M\"] = round((histogram[\"Count_1M\"] / histogram[\"Count_1M\"].sum()) * 100, 2)\n",
    "histogram[\"Count_2M\"] = round((histogram[\"Count_2M\"] / histogram[\"Count_2M\"].sum()) * 100, 2)\n",
    "histogram[\"Count_3M\"] = round((histogram[\"Count_3M\"] / histogram[\"Count_3M\"].sum()) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee09e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "most_pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
